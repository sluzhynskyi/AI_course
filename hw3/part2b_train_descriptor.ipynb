{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.8/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "class MNISTpairs(data.Dataset):\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset in pairs of similar(positive)/non-similar(negative) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):    \n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "        self.labels = self.mnist_dataset.train_labels\n",
    "        self.data = self.mnist_dataset.train_data                \n",
    "        # indices of images for each class\n",
    "        self.class_idx = [np.where(self.labels==x)[0] for x in range(0,10)]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # anchor image\n",
    "        img1, label1 = self.data[index], self.labels[index].item()\n",
    "        # draw another positive (1) or negative (0) image\n",
    "        pair_label = np.random.randint(0, 2)\n",
    "        \n",
    "        if pair_label == 1:\n",
    "            # choose an image with the same label as the anchor - avoid itself\n",
    "            index2 = index\n",
    "            while index2 == index:\n",
    "                index2 = np.random.choice(self.class_idx[label1])\n",
    "            img2 = self.data[index2]\n",
    "        else:\n",
    "            # choose an image with the different label than the anchor \n",
    "            img2 = self.data[np.random.choice(self.class_idx[ np.random.choice(np.setdiff1d(range(0,10), label1))])]\n",
    "            \n",
    "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        \n",
    "        return (img1, img2), pair_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    \n",
    "# mnist dataset structure - test part\n",
    "mnist_dataset_test = datasets.MNIST('vs3ex1data/mnist_data', train=False, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "    \n",
    "# mnist dataset structure - train part\n",
    "mnist_dataset_train = datasets.MNIST('vs3ex1data/mnist_data', train=True, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "            \n",
    "# mnist dataset in positive/negative pairs structure \n",
    "mnist_dataset_train_pairs = MNISTpairs(mnist_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2n(x, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Vector L2 normalization \n",
    "    \"\"\"\n",
    "    return x / (torch.norm(x, p=2, dim=1, keepdim=True) + eps).expand_as(x)\n",
    "\n",
    "class MnistNetEmb(nn.Module):\n",
    "    \"\"\"\n",
    "    Liteweight network architecture for the Mnist dataset (digit) to extract descriptors/embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MnistNetEmb, self).__init__()\n",
    "\n",
    "        # fully convolutional part\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, 4, kernel_size=5),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True)            \n",
    "        )\n",
    "        \n",
    "        # embedding network, FC layers\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Linear(16*4,16)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.embedder(x.view(-1,x.size(-3)*x.size(-2)*x.size(-1)))\n",
    "        return l2n(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, train_loader, optimizer, margin = 0.9):\n",
    "    \"\"\"\n",
    "    Training of an epoch with Contrastive loss and training pairs\n",
    "    model: network\n",
    "    train_loader: train_loader loading pairs of positive/negative images and pair-label in batches. \n",
    "    optimizer: optimizer to use in the training\n",
    "    margin: loss margin\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    all_neg_dist = torch.Tensor()\n",
    "    all_pos_dist = torch.Tensor()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # extract descriptor for anchor and the corresponding pos/neg images\n",
    "        v1, v2 = model(data[0]), model(data[1])\n",
    "        \n",
    "        # compute the contrastive loss\n",
    "        distances = (v2 - v1).pow(2).sum(1).sqrt()        \n",
    "        loss = 0.5 * (target.float() * distances.pow(2) + (1-target).float()*F.relu(margin - distances).pow(2))\n",
    "        \n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_neg_dist = torch.cat((all_neg_dist, distances[torch.nonzero(1-target)].view(-1))) # for statistics\n",
    "        all_pos_dist = torch.cat((all_pos_dist, distances[torch.nonzero(target)].view(-1))) # for statistics\n",
    "        total_loss = total_loss + loss.sum().data.numpy()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]\\tBatch loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.mean()))\n",
    "    print('Epoch average loss {:.6f}'.format(total_loss/len(train_loader.dataset)))\n",
    "\n",
    "    plt.hist(all_pos_dist.data.numpy(), 20, alpha = 0.5, label = 'pos')\n",
    "    plt.hist(all_neg_dist.data.numpy(), 20, alpha = 0.5, label = 'neg')\n",
    "    plt.title('Distribution of distances for positive and negative pairs')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def test(model, test_loader, step = 100):\n",
    "    \"\"\"\n",
    "    Compute accuracy on the test set\n",
    "    model: network\n",
    "    test_loader: test_loader loading images and labels in batches\n",
    "    step: step to iterate over images (for faster evaluation)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    des = torch.Tensor()\n",
    "    labels = torch.LongTensor()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        des = torch.cat((des, model(data)))\n",
    "        labels = torch.cat((labels, target))\n",
    "    \n",
    "    # compute all pair-wise distances\n",
    "    cdistances = cdist(des.data.numpy(), des.data.numpy(), 'euclidean')\n",
    "        \n",
    "    # find rank of closest positive image (using each descriptor as a query)\n",
    "    minrank_positive = []\n",
    "    for i in range(0,len(cdistances),step):\n",
    "        idx = np.argsort(cdistances[i])\n",
    "        minrank_positive.append( np.min([j for (j,x) in enumerate(labels[idx[1:-1]]) if x==labels[i]]) )\n",
    "    \n",
    "    print('Validation: At-least-1-pos@1 {:.3f}'.format((np.array(minrank_positive) <1).mean()))\n",
    "    print('Validation: At-least-1-pos@3 {:.3f}'.format((np.array(minrank_positive) <3).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the randomly initialized network\n",
      "Validation: At-least-1-pos@1 0.660\n",
      "Validation: At-least-1-pos@3 0.850\n"
     ]
    }
   ],
   "source": [
    "# loader of the training set in pairs\n",
    "train_loader_pairs = torch.utils.data.DataLoader(mnist_dataset_train_pairs,batch_size=64, shuffle=True)\n",
    "#loader of the test set (no pairs here)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dataset_test,batch_size=512, shuffle=False)\n",
    "\n",
    "model = MnistNetEmb() # initialize the network\n",
    "\n",
    "print('Validating the randomly initialized network')\n",
    "test(model, test_loader) # test the randomly initialized network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Contrastive loss and training pairs\n",
      "Epoch 1\n",
      "[0/60000 (0%)]\tBatch loss: 0.083642\n",
      "[200/60000 (11%)]\tBatch loss: 0.057310\n",
      "[400/60000 (21%)]\tBatch loss: 0.050416\n",
      "[600/60000 (32%)]\tBatch loss: 0.048984\n",
      "[800/60000 (43%)]\tBatch loss: 0.049992\n",
      "[1000/60000 (53%)]\tBatch loss: 0.040796\n",
      "[1200/60000 (64%)]\tBatch loss: 0.042715\n",
      "[1400/60000 (75%)]\tBatch loss: 0.039101\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print('Training with Contrastive loss and training pairs')\n",
    "# train with contrastive loss\n",
    "contrastive_margin = 0.9\n",
    "for epoch in range(1, 10 + 1):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        train2(model, train_loader_pairs, optimizer, contrastive_margin)\n",
    "        test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
