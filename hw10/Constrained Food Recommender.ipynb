{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained Food Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will implement both Content Based and Collaborative Filtering Recommenders and backtracking search (or local search) on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% finished homework should contain EDA, Item and User profiles generation, Content-Based Recommender, Collaborative Filtering Recommender, and soluton to CSP problem of assigning recommendations to brekfast, lunch and dinner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with subset of [Academic Yelp Dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset) containing list of restaurants in **yelp_business.csv** and reviews of the users in **yelp_reviews.parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_yelp_business = pd.read_csv(\"yelp_business.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "df_yelp_reviews = pd.read_parquet(\"yelp_reviews.parquet\")\n",
    "\n",
    "# Leave only users with at least 3 reviews\n",
    "users_count = df_yelp_reviews.groupby(\"user_id\").count()[[\"business_id\"]] \n",
    "users_to_use = users_count[users_count[\"business_id\"] > 2]\n",
    "df_yelp_reviews = df_yelp_reviews[df_yelp_reviews[\"user_id\"].isin(users_to_use.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will explore the data to find out what is the distribution of business categories, hours, places, user reviews, etc.\n",
    "\n",
    "This step is needed to proceed later with item and user profiling and to clean your data if there are duplicates (e.g. duplicated reviews, the same businesses under different ids, categories tags which are highly correlated) or some artifacts not related to the main task.\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_yelp_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all you should process user reviews to get the utility matrix containing ratings for users and businesses. There will be a lot of 0 in this matrix and it is better to store such matrices in the specialized data structure for sparce matrices. However, your working dataset is relatively small and we can use simple **pd.DataFrame** to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_utility_matrix(reviews: pd.DataFrame, business: pd.DataFrame) -> pd.DataFrame:\n",
    "    business_ids = business[\"business_id\"].unique()\n",
    "    users = reviews[\"user_id\"].unique()\n",
    "    ut_matrix = pd.DataFrame(0, columns=business_ids, index=users)\n",
    "    for _, review in reviews.iterrows():\n",
    "        ut_matrix.loc[review[\"user_id\"], review[\"business_id\"]] = review[\"stars\"]\n",
    "    # TODO: Rating normalization to (-1, 1) range (5 points)\n",
    "    return ut_matrix\n",
    "\n",
    "df_utility_matrix = create_utility_matrix(df_yelp_reviews, df_yelp_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_business_profiles(business: pd.DataFrame) -> pd.DataFrame:\n",
    "    # TODO: Feature engineering (10 points)\n",
    "    return pd.DataFrame(0, index=business[\"business_id\"].unique(), columns=[\"item_feature\"])\n",
    "\n",
    "df_business_profiles = build_business_profiles(df_yelp_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_user_profiles(utility_matrix: pd.DataFrame, \n",
    "                                   business_profiles: pd.DataFrame) -> pd.DataFrame:\n",
    "    # TODO: Feature aggregation (5 points)\n",
    "    return pd.DataFrame(0, index=utility_matrix.index, columns=business_profiles.columns)\n",
    "df_user_profiles = build_user_profiles(df_utility_matrix, df_business_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_content_ratings(user_profiles: pd.DataFrame, business_profiles: pd.DataFrame) -> pd.DataFrame:\n",
    "    # TODO: Distance based rating prediction (5 points)\n",
    "    # TODO: Pointwise/Pairwase training based prediction (optional for 10 extra points)\n",
    "    pass\n",
    "\n",
    "df_content_predictions = predict_content_ratings(df_user_profiles, df_business_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_collaborative_ratings(utility_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    # TODO: User-item collaborative filtering based rating prediction (15 points)\n",
    "    # TODO: UV-decomposition based rating prediction (optional for 10 extra points)\n",
    "    pass\n",
    "\n",
    "df_collaborative_predictions = predict_collaborative_ratings(df_utility_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_model(utility_matrix: pd.DataFrame, predicted_utility_matrix: pd.DataFrame, model_name=\"model_0\"):\n",
    "    # TODO: Implement these by hand (each metric 1 point)\n",
    "    rmse_score = 0\n",
    "    map_score = 0\n",
    "    coverage_score = 0\n",
    "    personalization_score = 0\n",
    "    intra_list_similarity_score = 0\n",
    "    \n",
    "    print(\"{} RMSE {}\".format(model_name, rmse_score))\n",
    "    print(\"MAP: {}\".format(model_name, map_score))\n",
    "    print(\"Coverage: {}\".format(model_name, coverage_score))\n",
    "    print(\"Personalization: {}\".format(model_name, personalization_score))\n",
    "    print(\"Intra-list similarity: {}\".format(model_name, intra_list_similarity_score))    \n",
    "\n",
    "score_model(df_content_predictions, df_utility_matrix, \"content-based approach\")\n",
    "score_model(df_collaborative_predictions, df_utility_matrix, \"collaborative-filtering approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint Satisfaction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the task of planing breakfast, lunch and dinner for particular user as Constraint Satisfaction Problem with\n",
    "\n",
    "**Domain**: {all_businesses}\n",
    "\n",
    "**Variables**: {breakfast, lunch, dinner}\n",
    "\n",
    "**Constraints**: {constrainst regarding individual variable, or several variables at once}\n",
    "\n",
    "We also have predicted ratings for every business and want to have personalized plan of restaurants. So we won't only satisfy our constraints, but also would like to get the maximum cumulative rating.\n",
    "\n",
    "Take a look on prepared constraints and finish empty constraints in similar way (some of these constraints may require analytics on business data. e.g. to finish **has_coffee_constraint** you may need to determine all the categories which may include good coffee in their menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_vegetarian_constraint(business_id):\n",
    "    return \"vegetarian\" in df_yelp_business[df_yelp_business[\"business_id\"] == business_id].categories.values[0].lower()\n",
    "\n",
    "def has_coffee_constraint(business_id):\n",
    "    # TODO: implement this constraint (1 point)\n",
    "    return False\n",
    "\n",
    "def has_alcohol_constraint(business_id):\n",
    "    # TODO: implement this constraint (1 point)\n",
    "    return False\n",
    "\n",
    "def is_open_constraint(business_id):\n",
    "    # TODO: implement this constraint (1 point)\n",
    "    return False\n",
    "\n",
    "def is_open_at_date_at_time_meta_constraint(weekday, time, business_id):\n",
    "    # TODO: implement this constraint (1 point)\n",
    "    return False\n",
    "\n",
    "def is_open_at_monday_at_10am_constraint(business_id):\n",
    "    return is_open_at_date_at_time(\"monday\", \"10:00\", business_id)\n",
    "\n",
    "def all_are_different_constraint(state):\n",
    "    for time in [\"breakfast\", \"dinner\", \"lunch\"]:\n",
    "        for _t in [\"breakfast\", \"dinner\", \"lunch\"]:\n",
    "            if time == _t: continue\n",
    "            business_categories = set(df_yelp_business[df_yelp_business[\"business_id\"] == state[time][\"business_id\"]].categories.values[0].split(\",\"))\n",
    "            _business_categories = set(df_yelp_business[df_yelp_business[\"business_id\"] == state[_t][\"business_id\"]].categories.values[0].split(\",\"))\n",
    "            if len(business_categories.intersection(_business_categories)) > \\\n",
    "                    len(business_categories.union(_business_categories)) // 2:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def all_are_in_the_same_city_constraint(state):\n",
    "    # TODO: implement this constraint (1 point)\n",
    "    return False\n",
    "\n",
    "def all_are_in_the_same_region_meta_constraint(coordinates, threshold, state):\n",
    "    # TODO: implement this constraint (1 point). Hint: use haversine distance https://pypi.org/project/haversine/\n",
    "    return False\n",
    "\n",
    "def all_are_in_test_region(state):\n",
    "    return all_are_in_the_same_region_constraint({\"lat\": 40.110446, \"lon\": -115.301568}, 400)\n",
    "\n",
    "def at_least_one_visited_place_constraint(state):\n",
    "    # TODO: implement this constraint (2 points)\n",
    "    # Make this constraint give more reward for more than one familiar place\n",
    "    return False\n",
    "\n",
    "def at_least_one_has_coffee_constraint(state):\n",
    "    # TODO: implement this constraint (2 points)\n",
    "    # Make this constraint give more reward for more than one place with coffee\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "random.seed(42)\n",
    "inspected_user = random.choice(df_yelp_reviews[\"user_id\"].unique())\n",
    "\n",
    "all_constraints = {\n",
    "    \"breakfast\": [has_coffee_constraint, is_open_constraint, is_open_at_monday_at_10am_constraint],\n",
    "    \"lunch\": [is_open_constraint],\n",
    "    \"dinner\": [is_vegetarian_constraint, has_alcohol_constraint, is_open_constraint],\n",
    "    \"state\": [at_least_one_has_coffee_constraint, at_least_one_visited_place_constraint, all_are_in_test_region,\n",
    "             all_are_in_the_same_city_constraint, all_are_different_constraint]\n",
    "}\n",
    "\n",
    "def goal_test(state: dict, constraints: dict):\n",
    "    cumulative_rating = state[\"breakfast\"][\"predicted_rating\"]*state[\"lunch\"][\"predicted_rating\"]*\\\n",
    "                        state[\"dinner\"][\"predicted_rating\"]\n",
    "    for k in constraints.keys():\n",
    "        if k == \"state\":\n",
    "            for c in constraints[k]:\n",
    "                cumulative_rating *= c(state)\n",
    "        else:\n",
    "            for c in constraints[k]:\n",
    "                cumulative_rating *= c(state[k][\"business_id\"])\n",
    "    return cumulative_rating\n",
    "\n",
    "\n",
    "def prepare_restaurants_plan(user_id: str, user_business_ratings: pd.DataFrame, constraints: dict):\n",
    "    # TODO: assign breakfast, lunch and dinner by solving Constraint Satisfaction Problem \n",
    "    # maximizing total score and satisfying all the constraints (it should work with any configuration of constraints)\n",
    "    \n",
    "    # You can implement Backtracking (10) + Filtering (10) + Ordering (5) using goal_test\n",
    "    # OR\n",
    "    # Local Search (10) + Min-Conflicts heuristic (10) + Ordering (5) with modification of goal test to work as Min-Conflicts heuristic\n",
    "    \n",
    "    state = {\"breakfast\": \n",
    "                {\"business_id\": random.choice(user_business_ratings[\"business_id\"].unique()),\n",
    "                 \"predicted_rating\": 0},\n",
    "            \"lunch\": \n",
    "    {\"business_id\": random.choice(user_business_ratings[\"business_id\"].unique()),\n",
    "                 \"predicted_rating\": 0},\n",
    "            \"dinner\": {\"business_id\": random.choice(user_business_ratings[\"business_id\"].unique()),\n",
    "                 \"predicted_rating\": 0}}\n",
    "    \n",
    "    state_v = goal_test(state, constraints)\n",
    "\n",
    "    \n",
    "    return state\n",
    "\n",
    "# TODO: replace df_utility_matrix with your best predictions\n",
    "prepare_restaurants_plan(inspected_user, df_utility_matrix, all_constraints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
